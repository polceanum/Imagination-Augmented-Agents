{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './common')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from common.actor_critic import ActorCritic\n",
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "from common.minipacman import MiniPacman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>USE CUDA</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pixels and Rewards</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Outputs of the Environment Model is trained to predict the next frame and reward by stochastic gradient decent on the Bernoulli cross-entropy between network outputs and data.<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#7 different pixels in MiniPacman\n",
    "pixels = (\n",
    "    (0.0, 1.0, 1.0),\n",
    "    (0.0, 1.0, 0.0), \n",
    "    (0.0, 0.0, 1.0),\n",
    "    (1.0, 1.0, 1.0),\n",
    "    (1.0, 1.0, 0.0), \n",
    "    (0.0, 0.0, 0.0),\n",
    "    (1.0, 0.0, 0.0),\n",
    ")\n",
    "pixel_to_categorical = {pix:i for i, pix in enumerate(pixels)} \n",
    "num_pixels = len(pixels)\n",
    "\n",
    "#For each mode in MiniPacman there are different rewards\n",
    "mode_rewards = {\n",
    "    \"regular\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    \"avoid\":   [0.1, -0.1, -5, -10, -20],\n",
    "    \"hunt\":    [0, 1, 10, -20],\n",
    "    \"ambush\":  [0, -0.1, 10, -20],\n",
    "    \"rush\":    [0, -0.1, 9.9]\n",
    "}\n",
    "reward_to_categorical = {mode: {reward:i for i, reward in enumerate(mode_rewards[mode])} for mode in mode_rewards.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pix_to_target(next_states):\n",
    "    target = []\n",
    "    for pixel in next_states.transpose(0, 2, 3, 1).reshape(-1, 3):\n",
    "        target.append(pixel_to_categorical[tuple([np.ceil(pixel[0]), np.ceil(pixel[1]), np.ceil(pixel[2])])])\n",
    "    return target\n",
    "\n",
    "def target_to_pix(imagined_states):\n",
    "    pixels = []\n",
    "    to_pixel = {value: key for key, value in pixel_to_categorical.items()}\n",
    "    for target in imagined_states:\n",
    "        pixels.append(list(to_pixel[target]))\n",
    "    return np.array(pixels)\n",
    "\n",
    "def rewards_to_target(mode, rewards):\n",
    "    target = []\n",
    "    for reward in rewards:\n",
    "        target.append(reward_to_categorical[mode][reward])\n",
    "    return target\n",
    "\n",
    "def plot(frame_idx, rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('loss %s' % losses[-1])\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "    \n",
    "def displayImage(image, step, reward):\n",
    "    s = str(step) + \" \" + str(reward)\n",
    "    plt.title(s)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Environment Model</h2>\n",
    "<p>The input and output frames are of size 3 x 15 x 19 (RGB x width x height). The model consisted of a size preserving, multi-scale CNN architecture with additional fully connected layers for reward prediction. <br>In order to capture long-range dependencies across pixels, we also make use of a layer called pool-and-inject, which applies global max-pooling over each\n",
    "feature map and broadcasts the resulting values as feature maps of the same size and concatenates the\n",
    "result to the input. Pool-and-inject layers are therefore size-preserving layers which communicate the\n",
    "max-value of each layer globally to the next convolutional layer.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_shape, n1, n2, n3):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        self.in_shape = in_shape\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "        self.n3 = n3\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=in_shape[1:])\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_shape[0] * 2, n1, kernel_size=1, stride=2, padding=6),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n1, n1, kernel_size=10, stride=1, padding=(5, 6)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_shape[0] * 2, n2, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n2, n2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(n1 + n2,  n3, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.pool_and_inject(inputs)\n",
    "        x = torch.cat([self.conv1(x), self.conv2(x)], 1)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.cat([x, inputs], 1)\n",
    "        return x\n",
    "    \n",
    "    def pool_and_inject(self, x):\n",
    "        pooled     = self.maxpool(x)\n",
    "        tiled      = pooled.expand((x.size(0),) + self.in_shape)\n",
    "        out        = torch.cat([tiled, x], 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EnvModel(nn.Module):\n",
    "    def __init__(self, in_shape, num_pixels, num_rewards):\n",
    "        super(EnvModel, self).__init__()\n",
    "        \n",
    "        width  = in_shape[1]\n",
    "        height = in_shape[2]\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(8, 64, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.basic_block1 = BasicBlock((64, width, height), 16, 32, 64)\n",
    "        self.basic_block2 = BasicBlock((128, width, height), 16, 32, 64)\n",
    "        \n",
    "        self.image_conv = nn.Sequential(\n",
    "            nn.Conv2d(192, 256, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.image_fc = nn.Linear(256, num_pixels)\n",
    "        \n",
    "        self.reward_conv = nn.Sequential(\n",
    "            nn.Conv2d(192, 64, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.reward_fc    = nn.Linear(64 * width * height, num_rewards)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        \n",
    "        x = self.conv(inputs)\n",
    "        x = self.basic_block1(x)\n",
    "        x = self.basic_block2(x)\n",
    "        \n",
    "        image = self.image_conv(x)\n",
    "        image = image.permute(0, 2, 3, 1).contiguous().view(-1, 256)\n",
    "        image = self.image_fc(image)\n",
    "\n",
    "        reward = self.reward_conv(x)\n",
    "        reward = reward.view(batch_size, -1)\n",
    "        reward = self.reward_fc(reward)\n",
    "        \n",
    "        return image, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating environments</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-5:\n",
      "Process Process-12:\n",
      "Process Process-7:\n",
      "Process Process-13:\n",
      "Process Process-10:\n",
      "Process Process-2:\n",
      "Process Process-6:\n",
      "Process Process-14:\n",
      "Process Process-16:\n",
      "Process Process-1:\n",
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Process Process-11:\n",
      "Process Process-8:\n",
      "Process Process-15:\n",
      "Process Process-9:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/mike/Work/DeepLearning/Imagination-Augmented-Agents/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "mode = \"regular\"\n",
    "num_envs = 16\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = MiniPacman(mode, 1000)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "state_shape = envs.observation_space.shape\n",
    "num_actions = envs.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env_model    = EnvModel(envs.observation_space.shape, num_pixels, len(mode_rewards[\"regular\"]))\n",
    "actor_critic = ActorCritic(envs.observation_space.shape, envs.action_space.n)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(env_model.parameters())\n",
    "\n",
    "if USE_CUDA:\n",
    "    env_model    = env_model.cuda()\n",
    "    actor_critic = actor_critic.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading pretrained Actor Critic from previous notebook.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_critic.load_state_dict(torch.load(\"actor_critic_\" + mode + \"_150k\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action(state):\n",
    "    if state.ndim == 4:\n",
    "        state = torch.FloatTensor(np.float32(state))\n",
    "    else:\n",
    "        state = torch.FloatTensor(np.float32(state)).unsqueeze(0)\n",
    "        \n",
    "    action = actor_critic.act(Variable(state, volatile=True))\n",
    "    action = action.data.cpu().squeeze(1).numpy()\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def play_games(envs, frames):\n",
    "    states = envs.reset()\n",
    "    \n",
    "    for frame_idx in range(frames):\n",
    "        actions = get_action(states)\n",
    "        next_states, rewards, dones, _ = envs.step(actions)\n",
    "        \n",
    "        yield frame_idx, states, actions, rewards, next_states, dones\n",
    "        \n",
    "        states = next_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAFRCAYAAACPNe3VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUkAK7iIiBaTgLiJSQP8fWpOd3ls2OEwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f067d36eac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reward_coef = 0.1\n",
    "num_updates = 5000\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "\n",
    "for frame_idx, states, actions, rewards, next_states, dones in play_games(envs, num_updates):\n",
    "    states      = torch.FloatTensor(states)\n",
    "    actions     = torch.LongTensor(actions)\n",
    "\n",
    "    batch_size = states.size(0)\n",
    "    \n",
    "    onehot_actions = torch.zeros(batch_size, num_actions, *state_shape[1:])\n",
    "    onehot_actions[range(batch_size), actions] = 1\n",
    "    inputs = Variable(torch.cat([states, onehot_actions], 1))\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        inputs = inputs.cuda()\n",
    "\n",
    "    imagined_state, imagined_reward = env_model(inputs)\n",
    "\n",
    "    target_state = pix_to_target(next_states)\n",
    "    target_state = Variable(torch.LongTensor(target_state))\n",
    "    \n",
    "    target_reward = rewards_to_target(mode, rewards)\n",
    "    target_reward = Variable(torch.LongTensor(target_reward))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    image_loss  = criterion(imagined_state, target_state)\n",
    "    reward_loss = criterion(imagined_reward, target_reward)\n",
    "    loss = image_loss + reward_coef * reward_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.data[0])\n",
    "    all_rewards.append(np.mean(rewards))\n",
    "    \n",
    "    if frame_idx % 10 == 0:\n",
    "        plot(frame_idx, all_rewards, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Saving the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(env_model.state_dict(), \"env_model_\" + mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imagination!</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAACsCAYAAABhCTuyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f067d4e9438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "env = MiniPacman(mode, 1000)\n",
    "batch_size = 1\n",
    "\n",
    "done = False\n",
    "state = env.reset()\n",
    "iss = []\n",
    "ss  = []\n",
    "\n",
    "steps = 0\n",
    "\n",
    "while not done:\n",
    "    steps += 1\n",
    "    actions = get_action(state)\n",
    "    onehot_actions = torch.zeros(batch_size, num_actions, *state_shape[1:])\n",
    "    onehot_actions[range(batch_size), actions] = 1\n",
    "    state = torch.FloatTensor(state).unsqueeze(0)\n",
    "    \n",
    "    inputs = Variable(torch.cat([state, onehot_actions], 1))\n",
    "    if USE_CUDA:\n",
    "        inputs = inputs.cuda()\n",
    "\n",
    "    imagined_state, imagined_reward = env_model(inputs)\n",
    "    imagined_state = F.softmax(imagined_state)\n",
    "    iss.append(imagined_state)\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(actions[0])\n",
    "    ss.append(state)\n",
    "    state = next_state\n",
    "    \n",
    "    imagined_image = target_to_pix(imagined_state.view(batch_size, -1, len(pixels))[0].max(1)[1].data.cpu().numpy())\n",
    "    imagined_image = imagined_image.reshape(15, 19, 3)\n",
    "    state_image = torch.FloatTensor(next_state).permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"Imagined\")\n",
    "    plt.imshow(imagined_image, interpolation='nearest')\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"Actual\")\n",
    "    plt.imshow(state_image, interpolation='nearest')\n",
    "    clear_output()\n",
    "    plt.show()\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    if steps > 30:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
